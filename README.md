# AJ (SO): Factored Cognition

## Basics

The key library we used Ought Ice, a mainstay library for [Factored Cognition](https://ought.org/research/factored-cognition)

## Intent

One aspect of scalable oversight is automated oversight, there have been some examples using models to evaluate question and mode outputs, we would like to do an instantiation of this particularly using factored cognition. We’d like a system that is general and self-directed both with respect inquires and topics of oversight.

## Details

1. Input: Prompt AND Answer
   1. Prompt could elicit an answer that alone seems harmless, but in the context of the prompt, is
2. Process:

## Ideas

1. Create a non-exhaustive list of safety-oriented questions based on each category of answer
2. Ask AI generate further questions based on (1)’s questions
3. Website to get query and answer and output if answer is ‘aligned’/safe or not
